{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Type Prediction (Sequential API NN)\n",
    "\n",
    "from:\n",
    "https://www.geeksforgeeks.org/prediction-of-wine-type-using-deep-learning/?ref=rp\n",
    "\n",
    "**Execuitve Summary**:\n",
    "- data : from UCI ML Repository. red and white wine csv with 11 features each\n",
    "- pre-work: merging the data, adding labels for red=1, white=0\n",
    "- model: Sequential Model, 2 hidden layers relu, 1 output layer with sigmoid and 1 unit since classification\n",
    "\n",
    "key-learnings / difficulties:\n",
    "- struggle with pandas/matplotlib, not working correctly in tensorflow env\n",
    "- pretty simple structure NN\n",
    "\n",
    "steps : \n",
    "    1. Data exploration\n",
    "    2. Alcohol Distribution in wines\n",
    "    3. set up NN and compile\n",
    "    4. Train and Predict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get the data\n",
    "\n",
    "white = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep =';') \n",
    "red = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep =';') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.854788</td>\n",
       "      <td>0.278241</td>\n",
       "      <td>0.334192</td>\n",
       "      <td>6.391415</td>\n",
       "      <td>0.045772</td>\n",
       "      <td>35.308085</td>\n",
       "      <td>138.360657</td>\n",
       "      <td>0.994027</td>\n",
       "      <td>3.188267</td>\n",
       "      <td>0.489847</td>\n",
       "      <td>10.514267</td>\n",
       "      <td>5.877909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.843868</td>\n",
       "      <td>0.100795</td>\n",
       "      <td>0.121020</td>\n",
       "      <td>5.072058</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>17.007137</td>\n",
       "      <td>42.498065</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.151001</td>\n",
       "      <td>0.114126</td>\n",
       "      <td>1.230621</td>\n",
       "      <td>0.885639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991723</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993740</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    4898.000000       4898.000000  4898.000000     4898.000000   \n",
       "mean        6.854788          0.278241     0.334192        6.391415   \n",
       "std         0.843868          0.100795     0.121020        5.072058   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.700000   \n",
       "50%         6.800000          0.260000     0.320000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.900000   \n",
       "max        14.200000          1.100000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  4898.000000          4898.000000           4898.000000  4898.000000   \n",
       "mean      0.045772            35.308085            138.360657     0.994027   \n",
       "std       0.021848            17.007137             42.498065     0.002991   \n",
       "min       0.009000             2.000000              9.000000     0.987110   \n",
       "25%       0.036000            23.000000            108.000000     0.991723   \n",
       "50%       0.043000            34.000000            134.000000     0.993740   \n",
       "75%       0.050000            46.000000            167.000000     0.996100   \n",
       "max       0.346000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  4898.000000  4898.000000  4898.000000  4898.000000  \n",
       "mean      3.188267     0.489847    10.514267     5.877909  \n",
       "std       0.151001     0.114126     1.230621     0.885639  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.090000     0.410000     9.500000     5.000000  \n",
       "50%       3.180000     0.470000    10.400000     6.000000  \n",
       "75%       3.280000     0.550000    11.400000     6.000000  \n",
       "max       3.820000     1.080000    14.200000     9.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine knowloedge\n",
    "\n",
    "- Sulfur (Sulfur dioxid) is additiv to preserve wine (can be reduced by less bad grapes and quick production procses, otherwise wine become vinegar)\n",
    "- Geschamcksangaben (dry, res. sugar below 4g (until 9g if total acidity max 2g lower than res. sugar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.isnull(red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Alcohol Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.subplots(nrows=1, ncols=1, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **fig_kw)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# error since installing tensorflow in new env 'tensorflow', \n",
    "# if notebook opened w/ base env same error\n",
    "plt=__import__(\"matplotlib.pyplot\")\n",
    "plt.pyplot.subplots\n",
    "\n",
    "#plt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'subplots'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-69f3d9552de4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create Histogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m ax[0].hist(red.alcohol, 10, facecolor ='red', \n\u001b[0;32m      5\u001b[0m \t\t\talpha = 0.5, label =\"Red wine\") \n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'subplots'"
     ]
    }
   ],
   "source": [
    "# Create Histogram \n",
    "fig, ax = plt.subplots(1, 2) \n",
    "\n",
    "ax[0].hist(red.alcohol, 10, facecolor ='red', \n",
    "\t\t\talpha = 0.5, label =\"Red wine\") \n",
    "\n",
    "ax[1].hist(white.alcohol, 10, facecolor ='white', \n",
    "\t\tec =\"black\", lw = 0.5, alpha = 0.5, \n",
    "\t\tlabel =\"White wine\") \n",
    "\n",
    "fig.subplots_adjust(left = 0, right = 1, bottom = 0, \n",
    "\t\t\ttop = 0.5, hspace = 0.05, wspace = 1) \n",
    "\n",
    "ax[0].set_ylim([0, 1000]) \n",
    "ax[0].set_xlabel(\"Alcohol in % Vol\") \n",
    "ax[0].set_ylabel(\"Frequency\") \n",
    "ax[1].set_ylim([0, 1000]) \n",
    "ax[1].set_xlabel(\"Alcohol in % Vol\") \n",
    "ax[1].set_ylabel(\"Frequency\") \n",
    "\n",
    "fig.suptitle(\"Distribution of Alcohol in % Vol\") \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preparation for Model\n",
    "\n",
    "# merge red and white df and add column for wine type\n",
    "red['type'] = 1\n",
    "white['type'] = 0\n",
    "  \n",
    "# Append `white` to `red` \n",
    "wines = red.append(white, ignore_index = True)\n",
    "\n",
    "# Split Data\n",
    "from sklearn.model_selection import train_test_split \n",
    "X = wines.iloc[:, 0:11] \n",
    "y = np.ravel(wines.type) \n",
    "  \n",
    "# Splitting the data set for training and validating  \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "           X, y, test_size = 0.34, random_state = 45) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 12)                144       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 9)                 117       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 271\n",
      "Trainable params: 271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_16',\n",
       " 'layers': [{'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_35',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 11),\n",
       "    'dtype': 'float32',\n",
       "    'units': 12,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_36',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 9,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_37',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3. Set up Neural Network using Sequential API\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Initialize the constructor \n",
    "model = Sequential() \n",
    "  \n",
    "# Add an input layer \n",
    "model.add(Dense(12, activation ='relu', input_shape =X_train.shape[1:])) \n",
    "  \n",
    "# Add one hidden layer \n",
    "model.add(Dense(9, activation ='relu')) \n",
    "  \n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation ='sigmoid')) \n",
    "  \n",
    "# Model output shape \n",
    "model.output_shape\n",
    "model.summary()\n",
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.31850958, -0.01643288,  0.3753947 , -0.3645296 , -0.14650881,\n",
       "          0.4843917 ,  0.2948625 , -0.32071185, -0.44664323,  0.26078045,\n",
       "          0.43748248, -0.0960418 ],\n",
       "        [ 0.05909884,  0.39824378,  0.22968364, -0.32365   ,  0.38172483,\n",
       "          0.33584154,  0.31592894, -0.379251  ,  0.49045336, -0.3473084 ,\n",
       "         -0.2255913 ,  0.21761882],\n",
       "        [ 0.3260188 , -0.1006577 ,  0.1316433 , -0.15042198,  0.14798653,\n",
       "          0.0173552 , -0.1597333 , -0.0080657 ,  0.36227107,  0.04194713,\n",
       "          0.2930224 , -0.09676051],\n",
       "        [ 0.36706364,  0.4514488 , -0.256284  ,  0.16978562,  0.38122976,\n",
       "          0.22012222, -0.48976398,  0.4882828 , -0.02063882, -0.29679513,\n",
       "          0.3222406 , -0.37905228],\n",
       "        [ 0.15823996,  0.35868585, -0.4614811 ,  0.01565194, -0.04697156,\n",
       "         -0.05682611,  0.29667497,  0.4847026 ,  0.23852861, -0.39294398,\n",
       "          0.21849322, -0.21433759],\n",
       "        [ 0.3761922 , -0.41922045, -0.48053157, -0.23666751,  0.2649436 ,\n",
       "          0.02355278, -0.33350933, -0.02793348,  0.14373505, -0.27473342,\n",
       "         -0.21961617, -0.11896729],\n",
       "        [-0.07126296,  0.19710875, -0.25121963,  0.13802373,  0.01662064,\n",
       "          0.43059373,  0.15472639, -0.07467735,  0.4229132 ,  0.14121354,\n",
       "         -0.2706467 , -0.3786081 ],\n",
       "        [-0.4668392 ,  0.07893777, -0.41535032,  0.311702  ,  0.09209859,\n",
       "         -0.04514098, -0.48310292,  0.4978609 ,  0.13409126, -0.10623097,\n",
       "         -0.11000156,  0.13025272],\n",
       "        [ 0.47544146, -0.11543238,  0.05647707,  0.07080138, -0.01488173,\n",
       "         -0.14474714,  0.41370666,  0.01370776,  0.4551431 ,  0.00504088,\n",
       "         -0.03418922,  0.07790935],\n",
       "        [ 0.13028753, -0.37624192, -0.1240083 , -0.27935994, -0.32043123,\n",
       "         -0.34797275,  0.47611415, -0.16834188,  0.2143346 , -0.27575624,\n",
       "          0.11352122, -0.24002099],\n",
       "        [ 0.21135771,  0.15834987,  0.4719913 ,  0.21866381, -0.01422513,\n",
       "         -0.17774916,  0.29637146,  0.36920333,  0.29161263, -0.3668617 ,\n",
       "         -0.19616008,  0.053123  ],\n",
       "        [ 0.3961029 ,  0.2624656 , -0.21397293, -0.23022807,  0.14511335,\n",
       "          0.45795095, -0.20819211, -0.25483036, -0.02040112,  0.2624768 ,\n",
       "         -0.235219  ,  0.42779016]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.16495603, -0.43837965,  0.5179066 ,  0.53066224, -0.2364183 ,\n",
       "         -0.08335322, -0.27137628,  0.07152081,  0.507667  ],\n",
       "        [-0.2363593 ,  0.43972015, -0.02713197, -0.5296996 ,  0.1699602 ,\n",
       "         -0.4688517 ,  0.12770325,  0.11352199,  0.45073724],\n",
       "        [-0.25793707, -0.24036515, -0.10922635, -0.13689652,  0.02390802,\n",
       "         -0.41858143,  0.4858274 , -0.5061892 , -0.43401533],\n",
       "        [ 0.24936724, -0.23675731,  0.38880163, -0.31359833, -0.08568791,\n",
       "          0.42921847, -0.32062474,  0.42141914, -0.46844786],\n",
       "        [ 0.16137367, -0.48153684, -0.27288976,  0.507909  ,  0.2300983 ,\n",
       "         -0.45363206, -0.15997133, -0.1578004 , -0.20679575],\n",
       "        [ 0.21908683, -0.20207116,  0.52630085, -0.15492752, -0.5063397 ,\n",
       "          0.26047635,  0.02132368, -0.42929786,  0.34636378],\n",
       "        [-0.3773026 , -0.5010366 ,  0.4103126 , -0.2902555 , -0.23597342,\n",
       "          0.51460534,  0.18844002, -0.07711756, -0.28562063],\n",
       "        [ 0.35889816, -0.43850148,  0.35709298,  0.28805578,  0.16811794,\n",
       "          0.43162215, -0.11089441,  0.43269426, -0.12767369],\n",
       "        [ 0.05331534, -0.4617245 , -0.0444335 , -0.2087712 , -0.29813233,\n",
       "         -0.20007953,  0.46397865,  0.03651172,  0.44686306],\n",
       "        [ 0.4259457 , -0.19605932,  0.43251026, -0.4354517 , -0.33766794,\n",
       "         -0.14411014, -0.16449022, -0.5309805 , -0.48378158],\n",
       "        [-0.3252377 ,  0.2606187 , -0.15574557,  0.49318892, -0.23192224,\n",
       "         -0.43812424,  0.0661664 , -0.15216193,  0.03600818],\n",
       "        [ 0.01824456, -0.48372638, -0.03127456,  0.11920226,  0.10441828,\n",
       "         -0.1442047 , -0.2452187 ,  0.49433678, -0.38209522]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.5037929 ],\n",
       "        [-0.6369916 ],\n",
       "        [ 0.08573687],\n",
       "        [-0.02828068],\n",
       "        [ 0.1002816 ],\n",
       "        [-0.07307774],\n",
       "        [-0.48929834],\n",
       "        [ 0.74365497],\n",
       "        [-0.39088148]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile the sequential model\n",
    "\n",
    "model.compile(loss= 'binary_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4288/4288 [==============================] - 10s 2ms/step - loss: 0.0696 - accuracy: 0.9764\n",
      "Epoch 2/10\n",
      "4288/4288 [==============================] - 9s 2ms/step - loss: 0.0627 - accuracy: 0.9778\n",
      "Epoch 3/10\n",
      "4288/4288 [==============================] - 9s 2ms/step - loss: 0.0643 - accuracy: 0.9788\n",
      "Epoch 4/10\n",
      "4288/4288 [==============================] - 9s 2ms/step - loss: 0.0641 - accuracy: 0.9774\n",
      "Epoch 5/10\n",
      "4288/4288 [==============================] - 9s 2ms/step - loss: 0.0628 - accuracy: 0.9809\n",
      "Epoch 6/10\n",
      "4288/4288 [==============================] - 9s 2ms/step - loss: 0.0610 - accuracy: 0.9813\n",
      "Epoch 7/10\n",
      "4288/4288 [==============================] - 9s 2ms/step - loss: 0.0646 - accuracy: 0.9783\n",
      "Epoch 8/10\n",
      "4288/4288 [==============================] - 9s 2ms/step - loss: 0.0648 - accuracy: 0.9778\n",
      "Epoch 9/10\n",
      "4288/4288 [==============================] - 9s 2ms/step - loss: 0.0560 - accuracy: 0.9825\n",
      "Epoch 10/10\n",
      "4288/4288 [==============================] - 9s 2ms/step - loss: 0.0574 - accuracy: 0.9827\n"
     ]
    }
   ],
   "source": [
    "## 4. Train and Predict\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, \n",
    "          batch_size=1, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00413684]\n",
      " [0.00985268]\n",
      " [0.00400945]\n",
      " [0.00380712]\n",
      " [0.00224266]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predict the test set\n",
    "\n",
    "y_pred = model.predict(X_test[:5])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(pd.DataFrame(history.history))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
